// Voice Module
import { socketService } from './socket-service.js';
import { t } from './translations.js';
import { iosCompatibility } from './ios-compatibility.js';

export class VoiceModule {
    constructor() {
        this.currentLanguage = 'en';
        console.log(`üåê VoiceModule initialized with language: ${this.currentLanguage}`);
        this.isConversationActive = false;
        this.isProcessingVoice = false;
        this.isSpeaking = false;
        this.conversationTimeout = null;
        this.conversationContext = [];
        this.lastInteractionTime = Date.now();
        this.wasInterrupted = false;
        
        // Audio recording variables
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.isRecording = false;
        this.audioStream = null;
        this.audioContext = null;
        this.analyser = null;
        this.microphone = null;
        this.recordingTimeout = null;
        
        // Audio playback tracking
        this.currentAudioSource = null;
        this.currentAudioContext = null;
        this.currentAudio = null;
        
        // Constants
        this.CONVERSATION_TIMEOUT = 150000; // 10 minutes
        this.RESPONSE_DELAY = 100;
        this.MAX_RECORDING_TIME = 7000; // 15 seconds
        this.SILENCE_DURATION = 1000; // 3 seconds
        
        this.setupEventListeners();
        this.setupWindowCloseListeners();
    }

    // Set current language
    setLanguage(language) {
        this.currentLanguage = language;
    }

    // Test backend connectivity
    async testBackendConnectivity() {
        try {
            console.log('üîç Testing backend connectivity...');
            const response = await fetch('/api/voice/config', {
                method: 'GET',
                headers: {
                    'Content-Type': 'application/json'
                }
            });
            
            if (response.ok) {
                const config = await response.json();
                console.log('‚úÖ Backend is accessible:', config);
            } else {
                console.warn('‚ö†Ô∏è Backend responded with status:', response.status);
            }
        } catch (error) {
            console.error('‚ùå Backend connectivity test failed:', error);
        }
    }

    // Setup event listeners
    setupEventListeners() {
        // Voice button - using dynamic onclick instead of event listener to avoid conflicts
        // This will be set up in the main app initialization
    }

    // Setup window close listeners for complete audio cleanup
    setupWindowCloseListeners() {
        console.log('üîß Setting up window close listeners for audio cleanup');
        
        // Handle window close/refresh
        window.addEventListener('beforeunload', () => {
            console.log('üö™ Window closing - performing complete audio cleanup');
            this.performCompleteAudioCleanup();
        });
        
        // Handle page unload
        window.addEventListener('unload', () => {
            console.log('üö™ Page unloading - performing complete audio cleanup');
            this.performCompleteAudioCleanup();
        });
        
        // Handle page hide (mobile browsers)
        document.addEventListener('pagehide', () => {
            console.log('üì± Page hiding - performing complete audio cleanup');
            this.performCompleteAudioCleanup();
        });
        
        // Handle visibility change to hidden (only stop if conversation is not active)
        document.addEventListener('visibilitychange', () => {
            if (document.hidden && !this.isConversationActive) {
                console.log('üëÅÔ∏è Page hidden and conversation not active - performing audio cleanup');
                this.performCompleteAudioCleanup();
            } else if (document.hidden && this.isConversationActive) {
                console.log('üëÅÔ∏è Page hidden but conversation active - keeping conversation running');
            }
        });
    }

    // Perform complete audio cleanup
    performCompleteAudioCleanup() {
        console.log('üßπ Performing complete audio cleanup');
        
        // Stop all voice activities
        this.stopVoiceConversation();
        
        // Emergency cleanup for any remaining audio
        this.emergencyAudioCleanup();
        
        console.log('‚úÖ Complete audio cleanup finished');
    }

    // Emergency audio cleanup for any remaining audio
    emergencyAudioCleanup() {
        console.log('üö® Emergency audio cleanup');
        
        // Stop ALL speech synthesis activities
        if (window.speechSynthesis) {
            try {
                window.speechSynthesis.cancel();
                window.speechSynthesis.pause();
                console.log('üîá Emergency: Speech synthesis stopped');
            } catch (e) {
                console.log('‚ö†Ô∏è Emergency: Speech synthesis cleanup failed');
            }
        }
        
        // Stop ALL audio playback
        if (window.currentAudio) {
            try {
                window.currentAudio.pause();
                window.currentAudio.currentTime = 0;
                window.currentAudio = null;
                console.log('üîá Emergency: Global audio stopped');
            } catch (e) {
                console.log('‚ö†Ô∏è Emergency: Global audio cleanup failed');
            }
        }
        
        // Stop ALL audio elements on the page
        const allAudioElements = document.querySelectorAll('audio');
        allAudioElements.forEach(audio => {
            try {
                audio.pause();
                audio.currentTime = 0;
            } catch (e) {
                console.log('‚ö†Ô∏è Emergency: Audio element cleanup failed');
            }
        });
        
        // Stop Web Audio API sources
        if (this.currentAudioSource) {
            try {
                this.currentAudioSource.stop();
                this.currentAudioSource.disconnect();
                this.currentAudioSource = null;
                console.log('üîá Emergency: Web Audio source stopped');
            } catch (e) {
                console.log('‚ö†Ô∏è Emergency: Web Audio source cleanup failed');
            }
        }
        
        // Close audio contexts
        if (this.currentAudioContext) {
            try {
                this.currentAudioContext.close();
                this.currentAudioContext = null;
                console.log('üîá Emergency: Audio context closed');
            } catch (e) {
                console.log('‚ö†Ô∏è Emergency: Audio context cleanup failed');
            }
        }
        
        if (window.audioContext) {
            try {
                window.audioContext.close();
                window.audioContext = null;
                console.log('üîá Emergency: Global audio context closed');
            } catch (e) {
                console.log('‚ö†Ô∏è Emergency: Global audio context cleanup failed');
            }
        }
        
        // Clear global references
        if (window.currentVoiceUtterance) {
            window.currentVoiceUtterance = null;
        }
        
        console.log('üö® Emergency audio cleanup completed');
    }

    // Start voice conversation
    startVoiceConversation() {
        console.log('üöÄ Starting voice conversation');
        
        // Test backend connectivity
        this.testBackendConnectivity();
        
        // Check security context
        const isSecureContext = window.isSecureContext || location.protocol === 'https:' || location.hostname === 'localhost' || location.hostname === '127.0.0.1';
        
        if (!isSecureContext) {
            console.warn('‚ö†Ô∏è Cannot start voice conversation: HTTPS required');
            this.handleRecordingError('https-required');
            return;
        }
        
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            console.warn('‚ö†Ô∏è Cannot start voice conversation: getUserMedia not supported');
            this.handleRecordingError('recording-failed');
            return;
        }
        
        this.isConversationActive = true;
        console.log('‚úÖ Conversation marked as ACTIVE');
        this.isProcessingVoice = false;
        this.isSpeaking = false;
        this.lastInteractionTime = Date.now();
        
        // Update UI
        this.updateVoiceButtonState('active');
        const listeningText = t('listening', this.currentLanguage);
        console.log(`üîç Translation result for 'listening': "${listeningText}" (language: ${this.currentLanguage})`);
        this.updateVoiceStatus(listeningText);
        this.updateVoiceAvatar('listening');
        this.showVoiceWaves(true);
        
        // Start the conversation with greeting
        this.playInitialGreeting(() => {
            if (this.isConversationActive) {
                this.startListening();
                this.resetConversationTimeout();
            }
        });
    }

    // Stop voice conversation
    stopVoiceConversation(force = false) {
        console.log('üõë Stopping voice conversation', force ? '(forced)' : '');
        console.log('üîç Current state before stop:', {
            isConversationActive: this.isConversationActive,
            isProcessingVoice: this.isProcessingVoice,
            isSpeaking: this.isSpeaking,
            isRecording: this.isRecording
        });
        
        // If not forced and conversation is active, ask for confirmation
        if (!force && this.isConversationActive) {
            console.log('‚ö†Ô∏è Conversation is active - stopping gracefully');
        }
        
        // Set all flags to false
        this.isConversationActive = false;
        console.log('‚ùå Conversation marked as INACTIVE');
        this.isProcessingVoice = false;
        this.isSpeaking = false;
        this.isRecording = false;
        
        // Stop microphone recording
        this.stopMicrophone();
        
        // Stop speech synthesis
        this.stopAllSpeechSynthesis();
        
        // Stop any ongoing audio playback
        this.stopAllAudioPlayback();
        
        // Clear all timeouts
        clearTimeout(this.conversationTimeout);
        clearTimeout(this.recordingTimeout);
        
        // Update UI
        this.updateVoiceButtonState('ready');
        this.updateVoiceAvatar('ready');
        this.showVoiceWaves(false);
        
        // Show end message
        const endMessage = this.currentLanguage === 'ar' ? 'ÿßŸÑŸÖÿ≠ÿßÿØÿ´ÿ© ÿßŸÑÿµŸàÿ™Ÿäÿ© ŸÖÿ™ŸàŸÇŸÅÿ©' : 'Voice conversation stopped';
        this.updateVoiceStatus(endMessage);
        
        // Quick transition back to ready state
        setTimeout(() => {
            this.updateVoiceStatus(t('voice-ready', this.currentLanguage));
        }, 1500);
    }

    // Stop microphone recording and release resources
    stopMicrophone() {
        console.log('üé§ Stopping microphone recording');
        
        // Stop media recorder
        if (this.mediaRecorder && this.mediaRecorder.state !== 'inactive') {
            try {
                this.mediaRecorder.stop();
                console.log('‚úÖ MediaRecorder stopped');
            } catch (e) {
                console.log('‚ö†Ô∏è MediaRecorder already stopped');
            }
        }
        
        // Stop audio stream tracks
        if (this.audioStream) {
            try {
                this.audioStream.getTracks().forEach(track => {
                    track.stop();
                    console.log('‚úÖ Audio track stopped');
                });
                this.audioStream = null;
            } catch (e) {
                console.log('‚ö†Ô∏è Audio stream already stopped');
            }
        }
        
        // Stop audio level monitoring
        this.stopAudioLevelMonitoring();
        
        // Clear audio chunks
        this.audioChunks = [];
        this.mediaRecorder = null;
        this.isRecording = false;
    }

    // Stop all speech synthesis
    stopAllSpeechSynthesis() {
        console.log('üîá Stopping all speech synthesis');
        
        if (window.speechSynthesis) {
            try {
                window.speechSynthesis.cancel();
                window.speechSynthesis.pause();
                console.log('‚úÖ Speech synthesis stopped');
            } catch (e) {
                console.log('‚ö†Ô∏è Speech synthesis already stopped');
            }
        }
        
        // Clear any global utterance references
        if (window.currentVoiceUtterance) {
            window.currentVoiceUtterance = null;
        }
    }

    // Stop all audio playback
    stopAllAudioPlayback() {
        console.log('üîá Stopping all audio playback');
        
        // Stop Web Audio API sources
        if (this.currentAudioSource) {
            try {
                this.currentAudioSource.stop();
                this.currentAudioSource.disconnect();
                this.currentAudioSource = null;
                console.log('‚úÖ Web Audio source stopped');
            } catch (e) {
                console.log('‚ö†Ô∏è Web Audio source already stopped');
            }
        }
        
        // Close audio context
        if (this.currentAudioContext) {
            try {
                this.currentAudioContext.close();
                this.currentAudioContext = null;
                console.log('‚úÖ Audio context closed');
            } catch (e) {
                console.log('‚ö†Ô∏è Audio context already closed');
            }
        }
        
        // Stop current audio
        if (this.currentAudio) {
            try {
                this.currentAudio.pause();
                this.currentAudio.currentTime = 0;
                this.currentAudio = null;
                console.log('‚úÖ Current audio stopped');
            } catch (e) {
                console.log('‚ö†Ô∏è Current audio already stopped');
            }
        }
        
        // Stop all audio elements on the page
        const allAudioElements = document.querySelectorAll('audio');
        allAudioElements.forEach(audio => {
            try {
                audio.pause();
                audio.currentTime = 0;
            } catch (e) {
                console.log('‚ö†Ô∏è Audio element already stopped');
            }
        });
        
        // Stop any global audio
        if (window.currentAudio) {
            try {
                window.currentAudio.pause();
                window.currentAudio.currentTime = 0;
                window.currentAudio = null;
            } catch (e) {
                console.log('‚ö†Ô∏è Global audio already stopped');
            }
        }
    }

    // Start listening
    startListening() {
        console.log('üé§ startListening() called - checking conditions:', {
            isConversationActive: this.isConversationActive,
            isRecording: this.isRecording,
            isProcessingVoice: this.isProcessingVoice,
            isSpeaking: this.isSpeaking
        });
        
        if (this.isConversationActive && !this.isRecording && !this.isProcessingVoice && !this.isSpeaking) {
            console.log('‚úÖ All conditions met - starting to listen...');
            console.log('üîç Current audio stream status:', {
                hasAudioStream: !!this.audioStream,
                audioStreamActive: this.audioStream ? this.audioStream.active : false,
                audioTracks: this.audioStream ? this.audioStream.getAudioTracks().length : 0
            });
            
            // Update UI for listening state
            this.updateVoiceAvatar('listening');
            this.showVoiceWaves(true);
            this.updateVoiceStatus(t('listening', this.currentLanguage));
            
            // Start audio recording
            this.startAudioRecording();
        } else {
            console.log('‚ùå Cannot start listening - conditions not met');
        }
    }

    // Start audio recording
    async startAudioRecording() {
        try {
            console.log('üé§ Requesting microphone access for Google Cloud...');
            
            // Check iOS compatibility first
            if (iosCompatibility.isIOS) {
                const hasPermission = await iosCompatibility.requestMicrophonePermission();
                if (!hasPermission) {
                    throw new Error('iOS microphone permission denied');
                }
            }
            
            // Use iOS-compatible audio constraints with higher quality
            const constraints = iosCompatibility.isIOS ? 
                iosCompatibility.getAudioConstraints() : 
                { 
                audio: {
                    sampleRate: 48000, // Higher sample rate for better quality
                    channelCount: 1,
                    echoCancellation: true,
                    noiseSuppression: true, // Enable noise suppression
                    autoGainControl: true,
                    latency: 0.01 // Low latency
                } 
                };
            
            this.audioStream = await navigator.mediaDevices.getUserMedia(constraints);
            
            console.log('‚úÖ Microphone access granted successfully');
            console.log('üîç Audio stream tracks:', this.audioStream.getAudioTracks().length);
            console.log('üîç Audio track settings:', this.audioStream.getAudioTracks()[0]?.getSettings());
            
            // Check microphone permissions
            const permissionStatus = await navigator.permissions.query({ name: 'microphone' });
            console.log('üîç Microphone permission status:', permissionStatus.state);
            
            // Test if microphone is actually working
            const audioTrack = this.audioStream.getAudioTracks()[0];
            if (audioTrack) {
                console.log('üîç Audio track state:', audioTrack.readyState);
                console.log('üîç Audio track enabled:', audioTrack.enabled);
                console.log('üîç Audio track muted:', audioTrack.muted);
            }
            
            // Set up audio level monitoring
            this.setupAudioLevelMonitoring(this.audioStream);
            
            // Create MediaRecorder with Google Cloud-compatible formats
            const options = { 
                audioBitsPerSecond: 128000, // Higher bitrate for better quality
                sampleRate: 48000, // Higher sample rate
                channelCount: 1 // Mono audio
            };
            
            // Try formats in order of Google Cloud compatibility (prefer WAV)
            const supportedFormats = [
                'audio/wav;codecs=1', // WAV with PCM codec
                'audio/wav',
                'audio/mp4;codecs=mp4a.40.2', // MP4 with AAC codec
                'audio/mp4',
                'audio/webm;codecs=opus', // WebM with Opus codec
                'audio/webm',
                'audio/ogg;codecs=opus', // OGG with Opus codec
                'audio/ogg'
            ];
            
            let selectedFormat = null;
            for (const mimeType of supportedFormats) {
                if (MediaRecorder.isTypeSupported(mimeType)) {
                    selectedFormat = mimeType;
                    break;
                }
            }
            
            if (selectedFormat) {
                options.mimeType = selectedFormat;
                console.log(`‚úÖ Using audio format: ${selectedFormat}`);
            }
            
            // Use iOS-compatible MediaRecorder if needed
            if (iosCompatibility.isIOS) {
                this.mediaRecorder = await iosCompatibility.createMediaRecorder();
            } else {
            this.mediaRecorder = new MediaRecorder(this.audioStream, options);
            }
            this.audioChunks = [];
            
            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                    console.log(`üì¶ Audio chunk collected: ${event.data.size} bytes`);
                }
            };
            
            this.mediaRecorder.onstop = () => {
                console.log('üõë Recording stopped, processing with Google Cloud...');
                this.processRecordedAudioWithGoogleCloud();
            };
            
            this.mediaRecorder.onerror = (error) => {
                console.error('‚ùå MediaRecorder error:', error);
                this.handleRecordingError('recording-failed');
            };
            
            // Start recording
            this.mediaRecorder.start(1000); // Collect data every second
            this.isRecording = true;
            
            console.log('üî¥ Recording started for Google Cloud');
            
            // Set maximum recording time
            this.recordingTimeout = setTimeout(() => {
                if (this.isRecording) {
                    console.log('‚è∞ Maximum recording time reached');
                    this.stopAudioRecording();
                }
            }, this.MAX_RECORDING_TIME);
            
            // Auto-stop after reasonable time
            setTimeout(() => {
                if (this.isRecording && !this.isSpeaking) {
                    console.log('üîá Auto-stopping after recording period (10 seconds)');
                    this.stopAudioRecording();
                }
            }, 7000);
            
        } catch (error) {
            console.error('‚ùå Failed to start recording:', error);
            this.handleRecordingError('recording-failed');
        }
    }

    // Stop audio recording
    stopAudioRecording() {
        if (this.mediaRecorder && this.isRecording) {
            console.log('‚èπÔ∏è Stopping audio recording...');
            
            clearTimeout(this.recordingTimeout);
            this.mediaRecorder.stop();
            this.isRecording = false;
            
            // Stop microphone stream
            if (this.audioStream) {
                this.audioStream.getTracks().forEach(track => track.stop());
                this.audioStream = null;
            }
            
            // Stop audio level monitoring
            this.stopAudioLevelMonitoring();
            
            const processingText = t('processing', this.currentLanguage);
            console.log(`üîç Translation result for 'processing': "${processingText}" (language: ${this.currentLanguage})`);
            this.updateVoiceStatus(processingText);
            this.updateVoiceButtonState('processing');
        }
    }

    // Process recorded audio with Google Cloud
    async processRecordedAudioWithGoogleCloud() {
        try {
            if (this.audioChunks.length === 0) {
                console.warn('‚ö†Ô∏è No audio data collected');
                if (this.isConversationActive) {
                    setTimeout(() => this.startListening(), 1000);
                }
                return;
            }
            
            console.log('üîÑ Creating audio blob for Google Cloud...');
            
            let mimeType = this.mediaRecorder?.mimeType || 'audio/webm';
            if (mimeType.includes('opus')) {
                mimeType = 'audio/ogg; codecs=opus';
            }
            
            const audioBlob = new Blob(this.audioChunks, { type: mimeType });
            console.log(`üéµ Audio blob created: ${audioBlob.size} bytes, type: ${mimeType}`);
            console.log(`üîç Audio chunks collected: ${this.audioChunks.length} chunks`);
            console.log(`üîç Total audio duration: ~${Math.round(audioBlob.size / 16000)} seconds (estimated)`);
            
            // Validate audio blob size
            if (audioBlob.size < 1000) {
                console.warn('‚ö†Ô∏è Audio blob is very small, might not contain speech');
            }
            
            // Check if we have any audio data
            if (this.audioChunks.length === 0) {
                console.error('‚ùå No audio chunks collected - microphone may not be working');
                if (this.isConversationActive) {
                    setTimeout(() => this.startListening(), 1000);
                }
                return;
            }
            
            // Log audio quality info
            console.log(`üîç Audio quality check: ${audioBlob.size} bytes, ${this.audioChunks.length} chunks, format: ${mimeType}`);
            
            // Send to Google Cloud
            await this.sendAudioToGoogleCloud(audioBlob, mimeType);
            
        } catch (error) {
            console.error('‚ùå Failed to process recorded audio:', error);
            this.handleRecordingError('processing-failed');
        }
    }

    // Send audio to Google Cloud Voice Pipeline (STT + RAG + TTS)
    async sendAudioToGoogleCloud(audioBlob, mimeType = 'audio/webm') {
        try {
            console.log('üì§ Sending audio to Google Cloud Voice Pipeline...');
            
            const formData = new FormData();
            const fileName = mimeType.includes('webm') ? 'recording.webm' : 
                            mimeType.includes('mp4') ? 'recording.mp4' : 'recording.wav';
            formData.append('audio', audioBlob, fileName);
            formData.append('language', this.currentLanguage === 'ar' ? 'ar' : 'en');
            
            // Call the complete voice pipeline endpoint (STT + RAG + TTS)
            const response = await fetch('/api/voice/process', {
                method: 'POST',
                body: formData
            });
            
            if (!response.ok) {
                throw new Error(`HTTP error! status: ${response.status}`);
            }
            
            const result = await response.json();
            console.log('üéØ Google Cloud Voice Pipeline response:', result);
            console.log('üîç Full pipeline response details:', JSON.stringify(result, null, 2));
            
            if (result.success) {
                // Check if we have a complete pipeline response
                if (result.pipeline && result.pipeline.stt && result.pipeline.stt.transcript && result.pipeline.stt.transcript.trim().length > 0) {
                    console.log('‚úÖ Complete voice pipeline successful:', result.pipeline.stt.transcript);
                    console.log('üß† RAG result:', result.pipeline.rag);
                    console.log('üîä TTS result:', result.pipeline.tts);
                    
                    // Use the complete pipeline response (STT + RAG + TTS)
                    this.handleCompleteVoiceResponse(result.pipeline);
                } else {
                    console.warn('‚ö†Ô∏è No speech detected in pipeline response');
                    console.log('üîç Pipeline structure:', result.pipeline);
                    const noSpeechMessage = this.currentLanguage === 'ar' 
                        ? 'ŸÑŸÖ ÿ£ÿ™ŸÖŸÉŸÜ ŸÖŸÜ ÿ≥ŸÖÿßÿπ ÿ£Ÿä ŸÉŸÑÿßŸÖ. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑÿ™ÿ≠ÿØÿ´ ÿ®Ÿàÿ∂Ÿàÿ≠ Ÿàÿ£ŸÇÿ±ÿ® ÿ•ŸÑŸâ ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ.'
                        : 'I couldn\'t hear any speech. Please speak clearly and closer to the microphone.';
                    
                    this.updateVoiceStatus(noSpeechMessage);
                    setTimeout(() => {
                        if (this.isConversationActive) {
                            this.updateVoiceStatus(t('listening', this.currentLanguage));
                            this.startListening();
                        }
                    }, 3000);
                }
            } else {
                console.error('‚ùå Pipeline failed:', result.error);
                throw new Error(`Google Cloud voice pipeline failed: ${result.error || 'Unknown error'}`);
            }
            
        } catch (error) {
            console.error('‚ùå Google Cloud voice pipeline error:', error);
            console.error('‚ùå Error details:', error.message);
            this.handleRecordingError('google-cloud-service-failed');
        }
    }
    // Handle complete voice pipeline response (STT + RAG + TTS)
    handleCompleteVoiceResponse(pipeline) {
        console.log('üéØ Processing complete voice pipeline response:', pipeline);
        
        const transcript = pipeline.stt?.transcript;
        const ragResponse = pipeline.rag?.response;
        const ttsAudio = pipeline.tts?.audioBuffer;
        
        if (transcript && transcript.trim().length > 0) {
            console.log('üó£Ô∏è User said:', transcript);
            
            // Add user message to conversation context
            this.conversationContext.push({
                role: 'user',
                message: transcript,
                timestamp: new Date().toISOString()
            });
            
            // Keep only last 8 messages
            if (this.conversationContext.length > 8) {
                this.conversationContext = this.conversationContext.slice(-8);
            }
            
            this.lastInteractionTime = Date.now();
            this.resetConversationTimeout();
            
            this.isProcessingVoice = true;
            this.updateVoiceStatus(t('processing', this.currentLanguage));
            this.updateVoiceButtonState('processing');
            this.updateVoiceAvatar('processing');
            this.showVoiceWaves(false);
            
            // Use RAG response only (no fallback)
            console.log('üß† RAG Response received:', ragResponse);
            console.log('üîç RAG Response type:', typeof ragResponse);
            console.log('üîç RAG Response length:', ragResponse ? ragResponse.length : 'null');
            
            if (!ragResponse) {
                console.error('‚ùå No RAG response received - this should not happen');
                const errorMessage = this.currentLanguage === 'ar' 
                    ? 'ÿπÿ∞ÿ±ÿßŸãÿå ÿ≠ÿØÿ´ ÿÆÿ∑ÿ£ ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±ŸÉ. Ÿäÿ±ÿ¨Ÿâ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ŸÖÿ±ÿ© ÿ£ÿÆÿ±Ÿâ.'
                    : 'Sorry, there was an error processing your query. Please try again.';
                this.updateVoiceStatus(errorMessage);
                setTimeout(() => {
                    if (this.isConversationActive) {
                        this.startListening();
                    }
                }, 3000);
                return;
            }
            
            const responseText = ragResponse;
            console.log('üéØ Final response text:', responseText);
            
            // Add AI response to conversation context
            this.conversationContext.push({
                role: 'assistant',
                message: responseText,
                timestamp: new Date().toISOString()
            });
            
            // Play TTS audio if available, otherwise use browser TTS
            if (ttsAudio) {
                this.playTTSAudio(ttsAudio, responseText);
            } else {
                this.speakTextContinuous(responseText, () => {
                    console.log('üîÑ TTS callback triggered - checking conversation state:', this.isConversationActive);
                    if (this.isConversationActive) {
                        console.log('üîÑ Restarting listening after response');
                        this.resetConversationTimeout(); // Reset timeout after AI response
                        setTimeout(() => {
                            this.startListening();
                        }, 300);
                    } else {
                        console.log('‚ùå Conversation not active - not restarting listening');
                    }
                });
            }
        } else {
            console.warn('‚ö†Ô∏è No transcript in pipeline response');
            // Don't end conversation, just restart listening
            if (this.isConversationActive) {
                this.updateVoiceStatus(t('listening', this.currentLanguage));
                this.updateVoiceButtonState('listening');
                this.updateVoiceAvatar('listening');
                this.showVoiceWaves(true);
                setTimeout(() => {
                    this.startListening();
                }, 1000);
            }
        }
    }

    // Play TTS audio from backend
    async playTTSAudio(base64Audio, responseText) {
        try {
            console.log('üîä Playing TTS audio from backend...');
            
            // Convert base64 to audio buffer
            const audioData = atob(base64Audio);
            const audioBuffer = new ArrayBuffer(audioData.length);
            const view = new Uint8Array(audioBuffer);
            
            for (let i = 0; i < audioData.length; i++) {
                view[i] = audioData.charCodeAt(i);
            }
            
            // Play audio
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const audioSource = audioContext.createBufferSource();
            const audioBufferData = await audioContext.decodeAudioData(audioBuffer);
            
            // Store references for interruption
            this.currentAudioSource = audioSource;
            this.currentAudioContext = audioContext;
            
            audioSource.buffer = audioBufferData;
            audioSource.connect(audioContext.destination);
            
            this.isSpeaking = true;
            this.updateVoiceStatus(t('speaking', this.currentLanguage));
            this.updateVoiceButtonState('speaking');
            this.updateVoiceAvatar('speaking');
            this.showVoiceWaves(false);
            
            audioSource.start();
            
            // When audio finishes, restart listening
            audioSource.onended = () => {
                console.log('‚úÖ Backend TTS audio playback completed');
                this.isSpeaking = false;
                this.isProcessingVoice = false; // Reset processing state
                
                // Clear audio source references
                this.currentAudioSource = null;
                this.currentAudioContext = null;
                
                if (this.isConversationActive) {
                    console.log('üîÑ Restarting listening after backend TTS audio');
                    this.resetConversationTimeout(); // Reset timeout after AI response
                    this.updateVoiceStatus(t('listening', this.currentLanguage));
                    this.updateVoiceButtonState('listening');
                    this.updateVoiceAvatar('listening');
                    this.showVoiceWaves(true);
                    setTimeout(() => {
                        this.startListening();
                    }, 300);
                } else {
                    console.log('‚ùå Conversation not active - not restarting listening after TTS');
                }
            };
            
        } catch (error) {
            console.error('‚ùå Error playing TTS audio:', error);
            // Fallback to browser TTS
            this.speakTextContinuous(responseText, () => {
                if (this.isConversationActive) {
                    setTimeout(() => {
                        this.startListening();
                    }, 300);
                }
            });
        }
    }

    // Handle transcription result (legacy method - kept for compatibility)
    handleTranscriptionResult(transcript) {
        console.log('üó£Ô∏è User said:', transcript);
        
        if (transcript.length > 0) {
            this.lastInteractionTime = Date.now();
            this.resetConversationTimeout();
            
            this.isProcessingVoice = true;
            this.updateVoiceStatus(t('processing', this.currentLanguage));
            
            // Add user message to conversation context
            this.conversationContext.push({
                role: 'user',
                message: transcript,
                timestamp: new Date().toISOString(),
                wasInterruption: this.wasInterrupted
            });
            
            // Reset interruption flag
            this.wasInterrupted = false;
            
            // Process the voice input
            this.processVoiceInputContinuous(transcript);
        } else {
            console.log('‚ö†Ô∏è Empty transcription, restarting listening...');
            if (this.isConversationActive) {
                setTimeout(() => this.startListening(), this.RESPONSE_DELAY);
            }
        }
    }

    // Process voice input continuously
    processVoiceInputContinuous(transcript) {
        console.log('üß† Processing voice input:', transcript);
        
        // Send to backend for processing via Socket.IO
        if (socketService.getConnectionStatus()) {
            console.log('üì§ Sending voice message via Socket.IO');
            
            const sent = socketService.sendVoiceMessage(
                transcript, 
                this.currentLanguage, 
                this.conversationContext
            );
            
            if (sent) {
                // Set up response handler
                const responseHandler = (response) => {
                    console.log('üì® Received RAG response from server:', response);
                    this.isProcessingVoice = false;
                    this.handleVoiceResponse(response.message || response);
                    
                    // Clean up listener
                    socketService.off('message-response', responseHandler);
                };
                
                socketService.onMessageResponse(responseHandler);
                
                // Timeout fallback
                setTimeout(() => {
                    if (this.isProcessingVoice) {
                        console.warn('‚è∞ Server response timeout - using fallback');
                        this.isProcessingVoice = false;
                        const localResponse = this.generateVoiceResponse(transcript);
                        this.handleVoiceResponse(localResponse);
                        socketService.off('message-response', responseHandler);
                    }
                }, 20000);
                
            } else {
                this.handleSendError(transcript);
            }
            
        } else {
            // Fallback to local processing
            console.log('üîå No socket connection, using local voice processing');
            setTimeout(() => {
                this.isProcessingVoice = false;
                const response = this.generateVoiceResponse(transcript);
                this.handleVoiceResponse(response);
            }, 1500);
        }
    }

    // Handle voice response
    handleVoiceResponse(responseText) {
        console.log('ü§ñ Bot responding:', responseText);
        
        // Add AI response to conversation context
        this.conversationContext.push({
            role: 'assistant',
            message: responseText,
            timestamp: new Date().toISOString()
        });
        
        // Keep only last 8 messages
        if (this.conversationContext.length > 8) {
            this.conversationContext = this.conversationContext.slice(-8);
        }
        
        // Update UI for processing
        this.updateVoiceAvatar('processing');
        this.showVoiceWaves(false);
        this.updateVoiceStatus(t('processing', this.currentLanguage));
        
        // Speak the response
        this.speakTextContinuous(responseText, () => {
            if (this.isConversationActive) {
                console.log('üîÑ Restarting listening after response');
                setTimeout(() => {
                    this.startListening();
                }, 300);
            }
        });
    }

    // Generate voice response (fallback)
    generateVoiceResponse(transcript) {
        const input = transcript.toLowerCase();
        let response = '';
        
        if (input.includes('hello') || input.includes('hi') || input.includes('ŸÖÿ±ÿ≠ÿ®ÿß') || input.includes('ÿßŸÑÿ≥ŸÑÿßŸÖ ÿπŸÑŸäŸÉŸÖ')) {
            response = this.currentLanguage === 'ar' 
                ? 'ŸÖÿ±ÿ≠ÿ®ÿßŸã! ÿ£ŸÜÿß ŸáŸÜÿß ŸÑŸÖÿ≥ÿßÿπÿØÿ™ŸÉ. ÿ™ÿ≠ÿØÿ´ ŸÖÿπŸä ÿ®ÿ≠ÿ±Ÿäÿ©ÿå ŸÖÿß ÿßŸÑÿ∞Ÿä ÿ™ÿ±ŸäÿØ ŸÖÿπÿ±ŸÅÿ™Ÿá ÿπŸÜ ÿßŸÑŸÉŸÑŸäÿ©ÿü'
                : 'Hi there! I\'m here to help you. Feel free to talk to me - what would you like to know about the college?';
        }
        else if (input.includes('department') || input.includes('ŸÇÿ≥ŸÖ') || input.includes('ÿ£ŸÇÿ≥ÿßŸÖ')) {
            response = this.currentLanguage === 'ar'
                ? 'ŸÑÿØŸäŸÜÿß 16 ŸÇÿ≥ŸÖÿßŸã ÿ±ÿßÿ¶ÿπÿßŸã. ÿ£Ÿä ŸÇÿ≥ŸÖ ŸäŸáŸÖŸÉÿü ŸäŸÖŸÉŸÜŸÜŸä ÿ•ÿÆÿ®ÿßÿ±ŸÉ ÿπŸÜ ÿßŸÑÿ∑ÿ®ÿå ÿßŸÑŸáŸÜÿØÿ≥ÿ©ÿå ÿßŸÑŸÑÿ∫ÿßÿ™ÿå ÿ£Ÿà ÿ£Ÿä ŸÇÿ≥ŸÖ ÿ¢ÿÆÿ±.'
                : 'We have 16 amazing departments! Which one interests you? I can tell you about medicine, engineering, languages, or any other department.';
        }
        else if (input.includes('fee') || input.includes('cost') || input.includes('price') || input.includes('ÿ±ÿ≥ŸàŸÖ') || input.includes('ÿ™ŸÉŸÑŸÅÿ©')) {
            response = this.currentLanguage === 'ar'
                ? 'ÿßŸÑÿ±ÿ≥ŸàŸÖ ÿ™ÿÆÿ™ŸÑŸÅ ÿ≠ÿ≥ÿ® ÿßŸÑŸÇÿ≥ŸÖ. ÿßŸÑÿ£ŸÇÿ≥ÿßŸÖ ÿßŸÑÿ∑ÿ®Ÿäÿ© ÿ£ÿ∫ŸÑŸâ ŸÇŸÑŸäŸÑÿßŸãÿå ŸÑŸÉŸÜŸáÿß ÿ™ÿ≥ÿ™ÿ≠ŸÇ ÿßŸÑÿßÿ≥ÿ™ÿ´ŸÖÿßÿ±. ÿ£Ÿä ŸÇÿ≥ŸÖ ÿ™ÿ±ŸäÿØ ŸÖÿπÿ±ŸÅÿ© ÿ±ÿ≥ŸàŸÖŸáÿü'
                : 'Fees vary by department. Medical departments are a bit more expensive, but they\'re worth the investment. Which department\'s fees are you curious about?';
        }
        else {
            const genericResponses = this.currentLanguage === 'ar' ? [
                'ÿ£ŸáŸÑÿßŸã! ÿ≥ÿ§ÿßŸÑŸÉ ŸÖÿ´Ÿäÿ± ŸÑŸÑÿßŸáÿ™ŸÖÿßŸÖ. ÿØÿπŸÜŸä ÿ£ÿ≥ÿßÿπÿØŸÉ ŸÅŸä ÿ∞ŸÑŸÉ.',
                'ŸÜÿπŸÖÿå Ÿáÿ∞ÿß ŸÖŸàÿ∂Ÿàÿπ ŸÖŸáŸÖ. ÿ•ŸÑŸäŸÉ ŸÖÿß ÿ£ÿπÿ±ŸÅŸá ÿπŸÜŸá.',
                'ŸÅŸáŸÖÿ™ÿå ÿ™ÿ±ŸäÿØ ŸÖÿπÿ±ŸÅÿ© ÿßŸÑŸÖÿ≤ŸäÿØ. Ÿáÿ∞ÿß ÿ±ÿßÿ¶ÿπ!',
                'ŸÖŸÖÿ™ÿßÿ≤! ÿ£ŸÜÿß ŸáŸÜÿß ŸÑŸÖÿ≥ÿßÿπÿØÿ™ŸÉ ŸÅŸä ÿ£Ÿä ÿßÿ≥ÿ™ŸÅÿ≥ÿßÿ±.',
                'ÿ±ÿßÿ¶ÿπ! ŸäŸÖŸÉŸÜŸÜŸä ÿ•ÿπÿ∑ÿßÿ§ŸÉ ŸÖÿπŸÑŸàŸÖÿßÿ™ ŸÖŸÅŸäÿØÿ© ÿπŸÜ ÿßŸÑŸÉŸÑŸäÿ©.'
            ] : [
                'That\'s interesting! Let me help you with that.',
                'Yes, that\'s an important topic. Here\'s what I can tell you.',
                'I understand you want to know more. That\'s great!',
                'Excellent! I\'m here to help with any questions.',
                'Great! I can provide you with useful information about the college.'
            ];
            
            response = genericResponses[Math.floor(Math.random() * genericResponses.length)];
        }
        
        return response;
    }

    // Speak text continuously
    speakTextContinuous(text, callback) {
        console.log('üó£Ô∏è Speaking with Google Cloud TTS:', text.substring(0, 50) + '...');
        
        this.isSpeaking = true;
        this.updateVoiceStatus(t('speaking', this.currentLanguage));
        this.updateVoiceButtonState('speaking');
        this.updateVoiceAvatar('speaking');
        this.showVoiceWaves(false);
        
        // Use Google Cloud TTS
        this.speakWithGoogleCloud(text, callback);
    }

    // Speak with Google Cloud TTS
    async speakWithGoogleCloud(text, callback) {
        try {
            console.log('üîä Converting text to speech with Google Cloud...');
            
            const response = await fetch('/api/voice/text-to-speech', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    text: text,
                    language: this.currentLanguage === 'ar' ? 'ar' : 'en',
                    voiceType: 'female'
                })
            });
            
            if (!response.ok) {
                throw new Error(`Google Cloud TTS API error: ${response.status}`);
            }
            
            const audioBuffer = await response.arrayBuffer();
            console.log(`‚úÖ Google Cloud TTS completed (${audioBuffer.byteLength} bytes)`);
            
            // Play audio
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const audioSource = audioContext.createBufferSource();
            const audioBufferData = await audioContext.decodeAudioData(audioBuffer);
            
            // Store references for interruption
            this.currentAudioSource = audioSource;
            this.currentAudioContext = audioContext;
            
            audioSource.buffer = audioBufferData;
            audioSource.connect(audioContext.destination);
            
            audioSource.onended = () => {
                console.log('‚úÖ Google Cloud TTS playback completed');
                this.isSpeaking = false;
                this.isProcessingVoice = false; // Reset processing state
                
                // Clear audio source references
                this.currentAudioSource = null;
                this.currentAudioContext = null;
                
                if (this.isConversationActive) {
                    this.updateVoiceStatus(t('listening', this.currentLanguage));
                    this.updateVoiceButtonState('listening');
                    this.updateVoiceAvatar('listening');
                    this.showVoiceWaves(true);
                }
                
                if (callback) {
                    console.log('üîÑ Calling TTS callback to restart listening...');
                    this.resetConversationTimeout(); // Reset timeout after AI response
                    setTimeout(callback, 200);
                }
            };
            
            audioSource.start();
            
        } catch (error) {
            console.error('‚ùå Google Cloud TTS error:', error);
            // Fallback to browser TTS
            this.speakWithBrowserTTS(text, callback);
        }
    }

    // Speak with browser TTS (fallback)
    speakWithBrowserTTS(text, callback) {
        if (!window.speechSynthesis) {
            if (callback) callback();
            return;
        }
        
        window.speechSynthesis.cancel();
        
        const utterance = new SpeechSynthesisUtterance(text);
        utterance.lang = this.currentLanguage === 'ar' ? 'ar-SA' : 'en-US';
        utterance.rate = 0.9;
        utterance.pitch = 1;
        utterance.volume = 0.8;
        
        utterance.onend = () => {
            console.log('‚úÖ Browser TTS completed');
            this.isSpeaking = false;
            
            if (this.isConversationActive) {
                this.updateVoiceStatus(t('listening', this.currentLanguage));
                this.updateVoiceButtonState('listening');
                this.updateVoiceAvatar('listening');
                this.showVoiceWaves(true);
            }
            
            if (callback) {
                console.log('üîÑ Calling browser TTS callback to restart listening...');
                this.resetConversationTimeout(); // Reset timeout after AI response
                setTimeout(callback, 200);
            }
        };
        
        window.speechSynthesis.speak(utterance);
    }

    // Play initial greeting
    async playInitialGreeting(callback) {
        try {
            console.log('üéØ Playing initial greeting...');
            
            const response = await fetch('/api/voice/initial-greeting', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    language: this.currentLanguage
                })
            });
            
            if (response.ok) {
                const data = await response.json();
                if (data.success) {
                    console.log('‚úÖ Initial greeting received:', data.greeting);
                    // Play the audio or use TTS
                    this.speakTextContinuous(data.greeting, callback);
                    return;
                }
            }
            
            // Fallback greeting
            const fallbackGreeting = this.currentLanguage === 'ar' 
                ? 'ŸÖÿ±ÿ≠ÿ®ÿßŸãÿå Ÿáÿ∞ÿß ŸÖŸÉÿ™ÿ® ÿßŸÑÿ•ÿØÿßÿ±ÿ© ŸÅŸä ŸÉŸÑŸäÿ© ÿ≥ŸÑÿ∑ÿßŸÜ ŸÑŸÑŸÅŸÜŸàŸÜ. ŸÉŸäŸÅ ŸäŸÖŸÉŸÜŸÜŸä ŸÖÿ≥ÿßÿπÿØÿ™ŸÉÿü'
                : 'Hi, this is the administration desk of SOA college. How can I help you?';
            this.speakTextContinuous(fallbackGreeting, callback);
            
        } catch (error) {
            console.error('‚ùå Error playing initial greeting:', error);
            const fallbackGreeting = this.currentLanguage === 'ar' 
                ? 'ŸÖÿ±ÿ≠ÿ®ÿßŸãÿå Ÿáÿ∞ÿß ŸÖŸÉÿ™ÿ® ÿßŸÑÿ•ÿØÿßÿ±ÿ© ŸÅŸä ŸÉŸÑŸäÿ© ÿ≥ŸÑÿ∑ÿßŸÜ ŸÑŸÑŸÅŸÜŸàŸÜ. ŸÉŸäŸÅ ŸäŸÖŸÉŸÜŸÜŸä ŸÖÿ≥ÿßÿπÿØÿ™ŸÉÿü'
                : 'Hi, this is the administration desk of SOA college. How can I help you?';
            this.speakTextContinuous(fallbackGreeting, callback);
        }
    }

    // Audio level monitoring
    setupAudioLevelMonitoring(stream) {
        try {
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
            this.analyser = this.audioContext.createAnalyser();
            this.microphone = this.audioContext.createMediaStreamSource(stream);
            
            this.analyser.fftSize = 256;
            const bufferLength = this.analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            this.microphone.connect(this.analyser);
            
            const checkAudioLevel = () => {
                if (this.analyser && this.isRecording) {
                    this.analyser.getByteFrequencyData(dataArray);
                    
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    const volume = average > 0 ? 20 * Math.log10(average / 255) : -Infinity;
                    
                    // Log audio level more frequently during recording
                    if (Math.random() < 0.3) { // 30% chance to log
                        console.log(`üé§ Audio level: ${volume.toFixed(1)} dB (avg: ${average.toFixed(1)})`);
                    }
                    
                    // Warn if audio level is very low
                    if (average < 5 && this.isRecording) {
                        console.warn(`‚ö†Ô∏è Very low audio level detected: ${average.toFixed(1)} (volume: ${volume.toFixed(1)} dB)`);
                    }
                    
                    requestAnimationFrame(checkAudioLevel);
                }
            };
            
            checkAudioLevel();
            console.log('‚úÖ Audio level monitoring started');
            
        } catch (error) {
            console.warn('‚ö†Ô∏è Audio level monitoring failed:', error);
        }
    }

    stopAudioLevelMonitoring() {
        if (this.microphone) {
            this.microphone.disconnect();
            this.microphone = null;
        }
        if (this.audioContext) {
            this.audioContext.close();
            this.audioContext = null;
        }
        this.analyser = null;
        console.log('üîá Audio level monitoring stopped');
    }

    // UI Update Methods
    updateVoiceButtonState(state) {
        const voiceBtn = document.getElementById('voiceBtn');
        const voiceBtnIcon = document.getElementById('voiceBtnIcon');
        const voiceBtnText = document.getElementById('voiceBtnText');
        
        if (!voiceBtn || !voiceBtnIcon || !voiceBtnText) return;
        
        // Remove all state classes
        voiceBtn.classList.remove('ready', 'active', 'listening', 'speaking', 'processing');
        
        switch(state) {
            case 'ready':
                voiceBtn.classList.add('ready');
                voiceBtnIcon.className = 'fas fa-play';
                voiceBtnText.textContent = 'Start Voice Assistant';
                voiceBtn.onclick = () => this.startVoiceConversation();
                break;
            case 'active':
                voiceBtn.classList.add('active');
                voiceBtnIcon.className = 'fas fa-microphone';
                voiceBtnText.textContent = 'Stop Voice Assistant';
                voiceBtn.onclick = () => this.stopVoiceConversation(); // Allow stopping conversation
                break;
            case 'listening':
                voiceBtn.classList.add('listening');
                voiceBtnIcon.className = 'fas fa-microphone';
                voiceBtnText.textContent = 'Listening...';
                voiceBtn.onclick = () => this.startListening();
                break;
            case 'speaking':
                voiceBtn.classList.add('speaking');
                voiceBtnIcon.className = 'fas fa-volume-up';
                voiceBtnText.textContent = 'Click to Interrupt';
                voiceBtn.onclick = () => this.interruptSpeaking(); // Allow interruption
                break;
            case 'processing':
                voiceBtn.classList.add('processing');
                voiceBtnIcon.className = 'fas fa-cog fa-spin';
                voiceBtnText.textContent = 'Thinking...';
                break;
        }
    }

    updateVoiceAvatar(state) {
        const voiceAvatar = document.getElementById('voiceAvatar');
        const voiceAvatarIcon = document.getElementById('voiceAvatarIcon');
        
        if (!voiceAvatar || !voiceAvatarIcon) return;
        
        voiceAvatar.classList.remove('listening', 'speaking', 'processing');
        
        switch(state) {
            case 'listening':
                voiceAvatar.classList.add('listening');
                voiceAvatarIcon.className = 'fas fa-microphone';
                break;
            case 'speaking':
                voiceAvatar.classList.add('speaking');
                voiceAvatarIcon.className = 'fas fa-volume-up';
                break;
            case 'processing':
                voiceAvatar.classList.add('processing');
                voiceAvatarIcon.className = 'fas fa-cog fa-spin';
                break;
            default:
                voiceAvatarIcon.className = 'fas fa-robot';
        }
    }

    showVoiceWaves(show) {
        const voiceWaves = document.getElementById('voiceWaves');
        if (voiceWaves) {
            if (show) {
                voiceWaves.classList.add('active');
            } else {
                voiceWaves.classList.remove('active');
            }
        }
    }

    updateVoiceStatus(status) {
        console.log(`üîÑ Updating voice status to: "${status}"`);
        const statusElement = document.getElementById('voiceStatus');
        if (statusElement) {
            const oldStatus = statusElement.textContent;
            statusElement.textContent = status;
            console.log(`‚úÖ Voice status updated successfully: "${oldStatus}" ‚Üí "${status}"`);
            console.log(`üîç Status element details:`, {
                id: statusElement.id,
                textContent: statusElement.textContent,
                innerHTML: statusElement.innerHTML,
                visible: statusElement.offsetParent !== null,
                display: window.getComputedStyle(statusElement).display
            });
            
            // Verify the update actually worked
            setTimeout(() => {
                const currentStatus = statusElement.textContent;
                if (currentStatus !== status) {
                    console.warn(`‚ö†Ô∏è Status was overridden: expected "${status}", got "${currentStatus}"`);
                    console.warn(`üîç Current element state:`, {
                        textContent: statusElement.textContent,
                        innerHTML: statusElement.innerHTML
                    });
                }
            }, 100);
        } else {
            console.error(`‚ùå Voice status element not found!`);
        }
    }

    // Interrupt speaking
    interruptSpeaking() {
        console.log('üñêÔ∏è User interrupted speaking');
        
        // Stop all speech synthesis
        this.stopAllSpeechSynthesis();
        
        // Stop all audio playback
        this.stopAllAudioPlayback();
        
        // Reset all speaking states
        this.isSpeaking = false;
        this.isProcessingVoice = false;
        this.wasInterrupted = true;
        
        // Clear audio source references
        this.currentAudioSource = null;
        this.currentAudioContext = null;
        
        if (this.isConversationActive) {
            this.updateVoiceStatus(this.currentLanguage === 'ar' ? 'ÿ™ŸÖ ÿßŸÑŸÖŸÇÿßÿ∑ÿπÿ© - ÿ£ÿ≥ÿ™ŸÖÿπ ÿßŸÑÿ¢ŸÜ' : 'Interrupted - listening now');
            this.updateVoiceButtonState('listening');
            this.updateVoiceAvatar('listening');
            this.showVoiceWaves(true);
            
            // Automatically start listening after interrupt
            setTimeout(() => {
                console.log('üîÑ Checking conditions for auto-start after interrupt:', {
                    isConversationActive: this.isConversationActive,
                    isSpeaking: this.isSpeaking,
                    isProcessingVoice: this.isProcessingVoice,
                    isRecording: this.isRecording,
                    audioStream: !!this.audioStream
                });
                
                if (this.isConversationActive && !this.isSpeaking && !this.isProcessingVoice) {
                    console.log('üîÑ Auto-starting listening after interrupt');
                    this.startListening();
                } else {
                    console.log('‚ùå Cannot auto-start listening - conditions not met');
                }
            }, 500); // Small delay to ensure audio cleanup is complete
        }
        
        console.log('‚úÖ Interrupt completed - audio stopped and state reset');
    }

    // Reset conversation timeout
    resetConversationTimeout() {
        clearTimeout(this.conversationTimeout);
        console.log('‚è∞ Resetting conversation timeout (10 minutes)');
        this.conversationTimeout = setTimeout(() => {
            console.log('‚è∞ Conversation timeout - ending conversation');
            console.log('‚è∞ Timeout triggered - conversation was active for 10 minutes');
            this.stopVoiceConversation();
        }, this.CONVERSATION_TIMEOUT);
    }

    // Handle recording errors
    handleRecordingError(errorType) {
        this.isRecording = false;
        this.isProcessingVoice = false;
        
        let errorMessage;
        let shouldEndConversation = false;
        
        switch(errorType) {
            case 'mic-access-denied':
                errorMessage = this.currentLanguage === 'ar' ? 'Ÿäÿ±ÿ¨Ÿâ ÿßŸÑÿ≥ŸÖÿßÿ≠ ÿ®ÿßŸÑŸàÿµŸàŸÑ ŸÑŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ' : 'Please allow microphone access';
                shouldEndConversation = true; // Critical error
                break;
            case 'recording-failed':
                errorMessage = this.currentLanguage === 'ar' ? 'ŸÅÿ¥ŸÑ ŸÅŸä ÿßŸÑÿ™ÿ≥ÿ¨ŸäŸÑ' : 'Recording failed';
                shouldEndConversation = false; // Non-critical, can retry
                break;
            case 'processing-failed':
                errorMessage = this.currentLanguage === 'ar' ? 'ŸÅÿ¥ŸÑ ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ™' : 'Audio processing failed';
                shouldEndConversation = false; // Non-critical, can retry
                break;
            case 'google-cloud-service-failed':
                errorMessage = this.currentLanguage === 'ar' ? 'ÿÆÿØŸÖÿ© ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿµŸàÿ™ ÿ∫Ÿäÿ± ŸÖÿ™ÿßÿ≠ÿ©' : 'Voice recognition service unavailable';
                shouldEndConversation = false; // Non-critical, can retry
                break;
            case 'https-required':
                errorMessage = this.currentLanguage === 'ar' ? 'ÿßŸÑŸÖŸäŸÉÿ±ŸàŸÅŸàŸÜ Ÿäÿ™ÿ∑ŸÑÿ® HTTPS ÿ£Ÿà localhost ŸÑŸÑÿπŸÖŸÑ' : 'Microphone requires HTTPS or localhost to work';
                shouldEndConversation = true; // Critical error
                break;
            case 'no-transcript':
                errorMessage = this.currentLanguage === 'ar' ? 'ŸÑŸÖ Ÿäÿ™ŸÖ ÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑŸÉŸÑÿßŸÖ' : 'No speech detected';
                shouldEndConversation = false; // Non-critical, can retry
                break;
            default:
                errorMessage = t('error-occurred', this.currentLanguage);
                shouldEndConversation = false; // Non-critical by default
        }
        
        this.updateVoiceStatus(errorMessage);
        
        if (shouldEndConversation) {
            // End conversation for critical errors
        this.isConversationActive = false;
        this.updateVoiceButtonState('ready');
        this.updateVoiceAvatar('ready');
        this.showVoiceWaves(false);
        
        setTimeout(() => {
            this.updateVoiceStatus(t('voice-ready', this.currentLanguage));
        }, 5000);
        } else {
            // For non-critical errors, just restart listening after a delay
            if (this.isConversationActive) {
                setTimeout(() => {
                    this.updateVoiceStatus(t('listening', this.currentLanguage));
                    this.updateVoiceButtonState('listening');
                    this.updateVoiceAvatar('listening');
                    this.showVoiceWaves(true);
                    this.startListening();
                }, 2000);
            }
        }
    }

    // Handle send error
    handleSendError(transcript) {
        this.isProcessingVoice = false;
        const localResponse = this.generateVoiceResponse(transcript);
        this.handleVoiceResponse(localResponse);
    }
}

// Export singleton instance
export const voiceModule = new VoiceModule();
